# File generated by CompCert 3.5
# Command line: ok_ckmultiargs.lus
	.data
	.align	3
	.globl	_self$
_self$:
	.space	1
	.data
	.align	3
	.globl	_w$
_w$:
	.space	1
	.data
	.align	3
	.globl	_x$
_x$:
	.space	1
	.data
	.align	3
	.globl	_a$
_a$:
	.space	1
	.data
	.align	3
	.globl	_b$
_b$:
	.space	1
	.data
	.align	3
	.globl	_c$
_c$:
	.space	1
	.text
	.align	4
	.globl _fun$mok$step
_fun$mok$step:
	.cfi_startproc
	subl	$28, %esp
	.cfi_adjust_cfa_offset	28
	leal	32(%esp), %eax
	movl	%eax, 0(%esp)
	movl	%ebx, 4(%esp)
	movl	%esi, 8(%esp)
	movl	%edi, 12(%esp)
	movl	16(%eax), %ebx
	movl	12(%eax), %edi
	movl	8(%eax), %ecx
	movl	4(%eax), %edx
	movl	0(%eax), %esi
	cmpl	$0, %ecx
	je	L100
	movzbl	0(%esi), %eax
	cmpl	$0, %eax
	setne	%al
	movzbl	%al, %eax
	movb	%al, 0(%edx)
	jmp	L101
L100:
	xorl	%eax, %eax
	movb	%al, 0(%edx)
L101:
	cmpl	$0, %ebx
	setne	%al
	movzbl	%al, %eax
	movb	%al, 0(%esi)
	cmpl	$0, %edi
	jne	L102
	xorl	%ecx, %ecx
	movb	%cl, 1(%edx)
	jmp	L103
L102:
	cmpl	$0, %ebx
	setne	%al
	movzbl	%al, %eax
	movb	%al, 1(%edx)
L103:
	movl	4(%esp), %ebx
	movl	8(%esp), %esi
	movl	12(%esp), %edi
	addl	$28, %esp
	ret
	.cfi_endproc
	.text
	.align	4
	.globl _fun$mok$reset
_fun$mok$reset:
	.cfi_startproc
	subl	$12, %esp
	.cfi_adjust_cfa_offset	12
	leal	16(%esp), %eax
	movl	%eax, 0(%esp)
	movl	0(%eax), %ecx
	xorl	%edx, %edx
	movb	%dl, 0(%ecx)
	addl	$12, %esp
	ret
	.cfi_endproc
	.text
	.align	4
	.globl _fun$kom$step
_fun$kom$step:
	.cfi_startproc
	subl	$28, %esp
	.cfi_adjust_cfa_offset	28
	leal	32(%esp), %eax
	movl	%eax, 0(%esp)
	movl	%ebx, 4(%esp)
	movl	%esi, 8(%esp)
	movl	%edi, 12(%esp)
	movl	20(%eax), %esi
	movl	16(%eax), %ecx
	movl	12(%eax), %ebx
	movl	8(%eax), %edi
	movl	4(%eax), %edx
	cmpl	$0, %edi
	jne	L104
	xorl	%ecx, %ecx
	movb	%cl, 0(%edx)
	jmp	L105
L104:
	cmpl	$0, %ecx
	setne	%cl
	movzbl	%cl, %ecx
	movb	%cl, 0(%edx)
L105:
	cmpl	$0, %ebx
	jne	L106
	xorl	%eax, %eax
	movb	%al, 1(%edx)
	jmp	L107
L106:
	cmpl	$0, %esi
	setne	%al
	movzbl	%al, %eax
	movb	%al, 1(%edx)
L107:
	movl	4(%esp), %ebx
	movl	8(%esp), %esi
	movl	12(%esp), %edi
	addl	$28, %esp
	ret
	.cfi_endproc
	.text
	.align	4
	.globl _fun$kom$reset
_fun$kom$reset:
	.cfi_startproc
	subl	$12, %esp
	.cfi_adjust_cfa_offset	12
	leal	16(%esp), %eax
	movl	%eax, 0(%esp)
	addl	$12, %esp
	ret
	.cfi_endproc
	.text
	.align	4
	.globl _fun$main$step
_fun$main$step:
	.cfi_startproc
	subl	$76, %esp
	.cfi_adjust_cfa_offset	76
	leal	80(%esp), %eax
	movl	%eax, 24(%esp)
	movl	%ebx, 28(%esp)
	movl	%esi, 32(%esp)
	movl	%edi, 36(%esp)
	movl	%ebp, 40(%esp)
	movl	16(%eax), %edi
	movl	12(%eax), %edx
	movl	%edx, 52(%esp)
	movl	8(%eax), %ebx
	movl	4(%eax), %edx
	movl	%edx, 56(%esp)
	movl	0(%eax), %edx
	movl	%edx, 48(%esp)
	leal	66(%esp), %esi
	cmpl	$0, %ebx
	setne	%al
	movzbl	%al, %eax
	movl	%eax, %ebp
	movl	52(%esp), %ecx
	cmpl	$0, %ecx
	setne	%dl
	movzbl	%dl, %edx
	cmpl	$0, %edi
	setne	%cl
	movzbl	%cl, %ecx
	movl	%ecx, 16(%esp)
	movl	%edx, 12(%esp)
	movl	%ebp, 8(%esp)
	movl	%esi, 4(%esp)
	movl	48(%esp), %eax
	movl	%eax, 0(%esp)
	call	_fun$mok$step
	movzbl	66(%esp), %edi
	movzbl	67(%esp), %ebp
	movl	48(%esp), %eax
	leal	1(%eax), %esi
	leal	64(%esp), %edx
	movl	%edx, 48(%esp)
	cmpl	$0, %ebx
	setne	%dl
	movzbl	%dl, %edx
	movl	52(%esp), %eax
	cmpl	$0, %eax
	setne	%bl
	movzbl	%bl, %ebx
	cmpl	$0, %edi
	setne	%al
	movzbl	%al, %eax
	movl	%eax, %edi
	cmpl	$0, %ebp
	setne	%cl
	movzbl	%cl, %ecx
	movl	%ecx, 20(%esp)
	movl	%edi, 16(%esp)
	movl	%ebx, 12(%esp)
	movl	%edx, 8(%esp)
	movl	48(%esp), %eax
	movl	%eax, 4(%esp)
	movl	%esi, 0(%esp)
	call	_fun$kom$step
	movzbl	64(%esp), %ecx
	cmpl	$0, %ecx
	setne	%al
	movzbl	%al, %eax
	movl	56(%esp), %ecx
	movb	%al, 0(%ecx)
	movzbl	65(%esp), %eax
	cmpl	$0, %eax
	setne	%cl
	movzbl	%cl, %ecx
	movl	56(%esp), %edx
	movb	%cl, 1(%edx)
	movl	28(%esp), %ebx
	movl	32(%esp), %esi
	movl	36(%esp), %edi
	movl	40(%esp), %ebp
	addl	$76, %esp
	ret
	.cfi_endproc
	.text
	.align	4
	.globl _fun$main$reset
_fun$main$reset:
	.cfi_startproc
	subl	$28, %esp
	.cfi_adjust_cfa_offset	28
	leal	32(%esp), %eax
	movl	%eax, 4(%esp)
	movl	%ebx, 8(%esp)
	movl	0(%eax), %ebx
	movl	%ebx, 0(%esp)
	call	_fun$mok$reset
	leal	1(%ebx), %eax
	movl	%eax, 0(%esp)
	call	_fun$kom$reset
	movl	8(%esp), %ebx
	addl	$28, %esp
	ret
	.cfi_endproc
	.text
	.align	4
	.globl _main_proved
_main_proved:
	.cfi_startproc
	subl	$44, %esp
	.cfi_adjust_cfa_offset	44
	leal	48(%esp), %eax
	movl	%eax, 20(%esp)
	movl	%ebx, 24(%esp)
	movl	%esi, 28(%esp)
	movl	%edi, 32(%esp)
	movl	%ebp, 36(%esp)
	leal	_self$, %eax
	movl	%eax, 0(%esp)
	call	_fun$main$reset
L108:
	movzbl	_a$, %eax
	movzbl	_b$, %esi
	movzbl	_c$, %ebp
	leal	_self$, %ebx
	leal	40(%esp), %edi
	cmpl	$0, %eax
	setne	%dl
	movzbl	%dl, %edx
	cmpl	$0, %esi
	setne	%al
	movzbl	%al, %eax
	movl	%eax, %esi
	cmpl	$0, %ebp
	setne	%al
	movzbl	%al, %eax
	movl	%eax, 16(%esp)
	movl	%esi, 12(%esp)
	movl	%edx, 8(%esp)
	movl	%edi, 4(%esp)
	movl	%ebx, 0(%esp)
	call	_fun$main$step
	movzbl	40(%esp), %eax
	cmpl	$0, %eax
	setne	%al
	movzbl	%al, %eax
	movb	%al, _w$
	movzbl	41(%esp), %eax
	cmpl	$0, %eax
	setne	%al
	movzbl	%al, %eax
	movb	%al, _x$
	jmp	L108
	.cfi_endproc
	.text
	.align	4
	.globl _main
_main:
	.cfi_startproc
	subl	$12, %esp
	.cfi_adjust_cfa_offset	12
	leal	16(%esp), %eax
	movl	%eax, 0(%esp)
	call	_main_proved
	movl	%ebx, %eax
	addl	$12, %esp
	ret
	.cfi_endproc
	.section __IMPORT,__pointers,non_lazy_symbol_pointers
